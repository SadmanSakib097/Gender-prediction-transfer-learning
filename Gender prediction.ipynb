{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5921f32",
   "metadata": {},
   "source": [
    "## Predicting Gender from Human or Non-human Social Media Profile Photos by using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "IMAGE_SIZE = [224,224]\n",
    "\n",
    "CLASS=2\n",
    "\n",
    "vgg16 = tf.keras.applications.VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = Flatten()(vgg16.output)\n",
    "\n",
    "prediction = Dense(CLASS, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer=adam,\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ec12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip= True)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224,224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical')\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (224,224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224,224),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = keras.optimizers.Adam(learning_rate=0.0001)  \n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer=op,\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "filepath = \"F:\\VGG16\\weights\\vgg16ep200batch16.h5\"\n",
    "\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "log_csv = CSVLogger('F:\\VGG16\\weights\\vgg16ep200batch16.csv', separator=',', append=False)\n",
    " \n",
    "    \n",
    "callbacks_list = [checkpoint1,log_csv]\n",
    "\n",
    "\n",
    "r = model.fit_generator(\n",
    "    training_set,\n",
    "    epochs=200,\n",
    "    validation_data=val_set,\n",
    "    steps_per_epoch = len(training_set),\n",
    "    validation_steps=len(val_set),\n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=False\n",
    "    \n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
